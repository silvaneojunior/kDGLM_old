---
title: "kDGLM: an R package for Bayesian analysis of Dynamic Generialized Linear Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{kDGLM: an R package for Bayesian analysis of Dynamic Generialized Linear Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

This vignette is intended as an introduction to use of the kDGLM package. This package aims to routines for Kalman filtering and smoothing, forecasting, sampling and Bayesian analysis of Dynamic Generalized Linear Models, following the theoretical results developed and/or explored in \cite{Kalman_filter_origins}, \cite{WestHarr-DLM} and \cite{ArtigokParametrico}. In this document we will focus exclusively in the usage of the package and will only briefly mention the theory behind these models and only with the intention of setting the notation. We highly recommend all users to read the theoretical work in which we based this package.

This document is organized in the following order: 

\begin{enumerate}
\item first we introduce the notations and the class of models we will be dealing with;
\item then we proceed to present the tools offered by our package to specify the model structure in an easy, fast and (hopefully) intuitive way;
\item in the following section we discuss how the user can specify the observational model; with the model structure defined, we can proceed presenting the tools for fitting a defined model, also showing the auxiliary function that help the user to analyse the fitted model;
\item in the next section we present a variety of more advanced examples, combining and stacking the basic structures shown in previous sections to create more complex models;
\item in this section, we show how the user can combine different types of outcomes in a same model to analyse multiple time series simultanously;
\item Lastly, we show how to make interventions on the model and also present the tools offered for automatic monitoring of time series.
\end{enumerate}

## Notation

Let us assume that the user is interested in analyzing a Time Serie $Y_t$, $t=1,...T$, in which we can be described by the following model:

$$
\begin{align}
Y_t|\theta_t &\sim \mathcal{F}\left(\eta_t\right),\\
g(\eta_t) &=\lambda_{t}=F_t'\theta_t,\\
\theta_t&=G_t\theta_{t-1}+\epsilon_t,\\
\epsilon_t &\sim \mathcal{N}(0,W^*_t),
\end{align}
$$
where:
\begin{itemize}
\item $\theta_t$ are the unknown parameter of interest;
\item $\mathcal{F}$ is a probability distribution in the Exponential Family and indexed by $\eta_t$;
\item $g$, called the link function, is a pre-specified function (in this package, each choice of $\mathcal{F}$ will have a pre-specified $g$);
\item $F_t$, called the design matrix, is a (mostly) known matrix specified by the user;
\item $G_t$, called the evolution matrix, is a (mostly) known matrix specified by the user;
\item $W^*_t$ is a known covariance matrix specified by the user.
\end{itemize}

Also, following the notation in \cite{WestHarr-DLM}, we will define $\mathcal{D}_t$ as the information one has after the first $t$ observations, such that $\mathcal{D}_t=\mathcal{D}_{t-1}\cup\{Y_t\}$ (for now, let's assume that there is not external source of information beside $Y_t$ itself) and $\mathcal{D}_0$ denotes the information we have about the process $Y_t$ *prior* to observing the data.

Notice that we **did not** make any assumptions on the dimension of $Y_t$ or $\eta_t$, indeed, this package offers tools for fitting time series made of vectors (as in the Multinomial case) ad/or with multiple unknown parameters (as in the Normal with unknown variance case).

Naturally, the manual specification of all the components of 

## The Normal model with known variance

We will consider the following model:

$$
\begin{align}
Y_t|\theta_t &\sim \mathcal{N}\left(\mu_t,\sigma^2\right),\\
\mu_t &=\lambda_{t}=F_t'\theta_t,\\
\theta_t&=G_t\theta_{t-1}+\epsilon_t,\\
\epsilon_t &\sim \mathcal{N}(0,\Sigma_t).
\end{align}
$$
where $Y_t$ is the observed outcome, $\theta_t$ is a vector of latent variables, $F_t$ and $G_t$ are (generally) known matrices, $\Sigma_t$ is a covariance matrix (i.e., symmetric and positive defined) and $\sigma^2$ is a known positive value.

We also will consider $\mathcal{D}_t$ as representing the knowledge we have after observing the data first $t$ time iterations. In this notation, we have that $\mathcal{D}_t=\{Y_t\} \cup D_{t-1}$, while $\mathcal{D}_0$ represent our prior knowledge about the phenomena we are studying.

To fit a model with this specification, the user must first specify the model structure. For this task, the package offers a variety of functions to allow the user to create pre-specified types of structures. For now, we will focus on the use of the `polynomial_block` function, whose usage syntax is as follows:

```{r eval=FALSE, include=TRUE}
polynomial_block(
  ...,
  order = 1,
  name = "Var_Poly",
  D = 1,
  W = 0,
  m0 = 0,
  C0 = c(NA, rep(1, order - 1))
)
```

This function will create a latent vector $\theta_t=(\theta_{1t},...,\theta_{k\ t})'$,, where $k$ is the order of the polynomial block, so that:

$$
\begin{align}
\theta_{it} &= \theta_{it-1}+\theta_{i+1\ t-1}+\epsilon_{it},\\
\theta_{kt} &= \theta_{kt-1}+\epsilon_{kt},\\
\theta_1&\sim \mathcal{N}_k(m_0,C_0),\\
\epsilon_{1t},...,\epsilon_{kt}&\sim \mathcal{N}_k(0,\Sigma_t),
\end{align}
$$
where $\Sigma_t=\frac{1-D_t}{D_t}Var[\theta_t|\mathcal{D}_{t-1}]+W_t$.

Notice that the user do not need to specify the matrix $G_t$, since it is implicitly determined by the order of the polynomial block (each type of block will define it own matrix $G_t$).

It is easy to see the correspondence between most of the arguments of the `polynomial_block` function and their respective meaning in the block specification, remaining only to explain the use of the `...` and `name` arguments.

The argument `...` is used to specify the matrix $F_t$, specifically, the user must provide a list of named values, whose name indicate a linear predictor $\lambda_t$ and it's associated value represent the effect of $\theta_{1t}$ in this predictor. Naturally, if a linear predictor is not present in `...`, it is understood that $\theta_{1t}$ have no effect whatsoever in that linear predictor. It may seem strange such specification of $F_t$, but as the reader will see further bellow (and in other types of models, specilly the ones with multiple outcomes), this way of specifying $F_t$ is very useful to avoid confusion when dealing with multiple linear predictors.

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(kDGLM)
```


$$
\begin{align}
Y_t|\theta_t &\sim \mathcal{N}\left(\mu_t,\tau_t^{-1}\right),\\
\begin{bmatrix}\mu_t\\\ln(\tau_t)\end{bmatrix} &=\begin{bmatrix}\lambda_{1t}\\\lambda_{2t}\end{bmatrix}=F_t'\theta_t,\\
\theta_t&=G_t\theta_{t-1}+\epsilon_t,\\
\epsilon_t &\sim \mathcal{N}(0,\Sigma_t).
\end{align}
$$
