---
title: "Comparação Gamma"
author: "Silvaneo Viera dos Santos Junior"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
devtools::load_all()

library(extrafont)
loadfonts(device = "win")
library(extraDistr)
library(latex2exp)

font_size=12
family_font='serif'
mult_scale=2

base.h=540
base.w=960

# Dados IBM
data=read.csv('C:/Jupyter/Mestrado/Pacote/GDLM/data/m-ibmln.txt')

T = dim(data)[1]
y <- data[,1]
year <- seq(as.Date("1926/10/1"), by = "month", length.out = T)
year_label <- seq(as.Date("1930/1/1"), by = "10 years", length.out = 8)

sample_size=2000
```

Os dados observados são os retornos da IBM. 3 modelos foram ajustados para os dados:

- Ajuste Normal: Nesse caso, usamos o modelo observacional $y_i|\mu_i,\sigma_i^2 \sim \mathcal{N}(\mu_i,\sigma_i)$ e estimamos $\mu_i$ e $\sigma_i$ usando a abordagem $k$-paramétrica para o caso Normal com variância desconhecida.
- Ajuste Gamma: Nesse caso, usamos o modelo observacional $(y_i-\bar{y})^2|\phi_i,\mu_i \sim \mathcal{G}\left(\phi_i,\frac{\phi_i}{\mu_i}\right)$. Dado a natureza dos dados, seria razoável usar $0$ no lugar de $\bar{y}$, pois é comum assumir que a média dos retornos é nula, porém, algumas das observações são **exatamente** $0$, o que causa problemas no ajuste. Para estimar $\phi_i$ e $\mu_i$ usamos a abordagem $k$-paramétrica para o caso Gamma com média e forma desconhecidas.
- Ajuste Gamma com Gibbs: Nesse caso, usamos o também usamos o modelo observacional $(y_i-\bar{y})^2|\phi_i,\mu_i \sim \mathcal{G}\left(\phi,\frac{\phi}{\mu}\right)$, porém, para realizar o ajuste, usamos o algoritmo de Gibbs, amostrando $\phi_i$ dado os $\mu_i$'s e as observações e depois amostramos $\mu_i$ dado os $\phi_i$'s e as observações. Esse modelo é equivalente ao ajuste Gamma, a única diferença sendo a forma de estimação dos parâmetros, sendo que o ajuste com Gibbs é mais preciso (a posteriori obtida é mais próxima da posteriori verdadeira) porém muito mais custoso e sem a propriedade de ser sequencial (caso novos dados sejam observados, seria necessário refazer o ajuste desde o começo).

No gráfico a seguir exibimos $(y_i-\bar{y})^2$ contra o seu valor esperado e os intervalos de credibilidade de $95\%$ para cada um dos ajustes feitos.

```{r Normal gamma}
level=polynomial_block(order=1,value=c(1,0),D=1/1,by_time = F)
volatility1=polynomial_block(order=1,value=c(0,1),D=1/1,by_time = F)
volatility2=AR_block(order=1,value=c(0,1),D=1/1,W=diag(c(0.1,0)),by_time = F)

fitted_data=fit_model(level,volatility1,volatility2,outcome=y,family='Normal_Gamma_cor')

sample_NG=FFBS_sampling(fitted_data,sample_size)

NG_pred=rep(NA,T)
NG_icl=rep(NA,T)
NG_icu=rep(NA,T)
for(t in 1:T){
  sample_norm=rnorm(sample_size,sample_NG$param[1,t,],sqrt(1/sample_NG$param[2,t,]))
  NG_pred[t]=mean((sample_norm-sample_NG$param[1,t,])**2)
  NG_icu[t]=quantile((sample_norm-sample_NG$param[1,t,])**2,0.975)
  NG_icl[t]=quantile((sample_norm-sample_NG$param[1,t,])**2,0.025)
}
```

```{r Gamma gibbs}
# densi_conj=function(x,tau,k){
#   p1=k*(x*log(x)-lgamma(x))
#   return(-tau*x+p1)
# }
# outcome=(y-mean(y))**2
# 
# phi=1/2
# mu=mean(outcome)
# 
# tau_0=1
# k_0=1
# 
# phi_sample=rep(NA,sample_size)
# mu_sample=matrix(NA,T,sample_size)
# mt_sample=matrix(NA,T,sample_size)
# pred_sample=matrix(NA,T,sample_size)
# 
# mu_i=mean(outcome)
# phi_i=1/2
# gamma_size=sample_size
# gamma_sample=rgamma(gamma_size,(T/2),(T/2)/phi_i)
# gamma_densi=dgamma(gamma_sample,(T/2),(T/2)/phi_i,log=TRUE)
# 
# alpha_prop=(T/2)
# beta_prop=(T/2)/phi_i
# 
# volatility1=polynomial_block(order=1,value=1,D=1/1,by_time = F)
# volatility2=AR_block(order=1,value=1,D=1/1,W=diag(c(0.1,0)),by_time = F)
# 
# for(i in 1:sample_size){
#   cat(paste0(i,'                          \r'))
#   fitted_model=fit_model(volatility1,volatility2,outcome=outcome,parms=list('phi'=phi_i),family='gamma',pred_cred=-1,smooth_flag = FALSE)
#   sample=FFBS_sampling(fitted_model,1)
#   mu_i=sample$param
# 
#   tau_i=tau_0+sum(outcome/mu_i-log(outcome/mu_i))
#   k_i=k_0+T
# 
#   weights_unscaled=densi_conj(gamma_sample,tau_i,k_i)-gamma_densi
# 
#   weights_raw=exp(weights_unscaled-max(weights_unscaled))
#   weights=weights_raw/sum(weights_raw)
#   phi_i=sample(gamma_sample,1,prob=weights)
# 
#   alpha_prop=(T/2)
#   beta_prop=(T/2)/sum(weights*gamma_sample)
# 
#   gamma_sample=rgamma(gamma_size,alpha_prop,beta_prop)
#   gamma_densi=dgamma(gamma_sample,alpha_prop,beta_prop,log=TRUE)
#   pred_i=rgamma(T, phi_i, phi_i/mu_i[1,,1])
# 
#   mu_sample[,i]=mu_i[1,,]
#   mt_sample[,i]=sample$mt[1,,]
#   phi_sample[i]=phi_i
#   pred_sample[,i]=pred_i
# }
# 
# save(file='pred_sample.Rdata',pred_sample)
```

```{r}
load(file='pred_sample.Rdata')
mean_gamma_gibbs=rep(NA,T)
icl_gamma_gibbs=rep(NA,T)
icu_gamma_gibbs=rep(NA,T)

for(t in 1:T){
  mean_gamma_gibbs[t]=(mean(pred_sample[t,]))
  icu_gamma_gibbs[t]=(quantile(pred_sample[t,],0.975))
  icl_gamma_gibbs[t]=(quantile(pred_sample[t,],0.025))
}
```


```{r Gamma}
devtools::load_all()
level=polynomial_block(order=1,value=c(1,0),D=1/1,by_time = F)
volatility1=polynomial_block(order=1,value=c(0,1),D=1/1,by_time = F)
volatility2=AR_block(order=1,value=c(0,1),D=1/1,W=diag(c(0.1,0)),by_time = F)

outcome=(y-mean(y))**2
a=mean(outcome)
outcome=outcome/a

fitted_data=fit_model(level,volatility1,volatility2,outcome=outcome,family='FGamma')

sample=FFBS_sampling(fitted_data,sample_size)

pred=rep(NA,T)
icu=rep(NA,T)
icl=rep(NA,T)
for(t in 1:T){
  sample_gamma=a*rgamma(sample_size,shape=sample$param[1,t,],rate=sample$param[1,t,]/sample$param[2,t,])
  pred[t]=mean(sample_gamma)
  icu[t]=quantile(sample_gamma,0.975)
  icl[t]=quantile(sample_gamma,0.025)
}
```

```{r Gamma2}
devtools::load_all()
level=polynomial_block(order=1,value=c(1,0),D=1/1,by_time = F)
volatility1=polynomial_block(order=1,value=c(0,1),D=1/1,by_time = F)
volatility2=AR_block(order=1,value=c(0,1),D=1/1,W=diag(c(0.1,0)),by_time = F)

outcome=(y-mean(y))**2
a=mean(outcome)
outcome=outcome/a

fitted_data=fit_model(level,volatility1,volatility2,outcome=outcome,family='FGamma2')

sample=FFBS_sampling(fitted_data,sample_size)

pred2=rep(NA,T)
icu2=rep(NA,T)
icl2=rep(NA,T)
for(t in 1:T){
  sample_gamma=a*rgamma(sample_size,shape=sample$param[1,t,],rate=sample$param[1,t,]/sample$param[2,t,])
  pred2[t]=mean(sample_gamma)
  icu2[t]=quantile(sample_gamma,0.975)
  icl2[t]=quantile(sample_gamma,0.025)
}
```

```{r Gamma2half}
devtools::load_all()
level=polynomial_block(order=1,value=c(1,0),D=1/1,by_time = F)
volatility1=polynomial_block(order=1,value=c(0,1),D=1/1,by_time = F)
volatility2=AR_block(order=1,value=c(0,1),D=1/1,W=diag(c(0.1,0)),by_time = F)

outcome=(y-mean(y))**2
a=mean(outcome)
outcome=outcome/a

fitted_data=fit_model(level,volatility1,volatility2,outcome=outcome,family='FGamma3')

sample=FFBS_sampling(fitted_data,sample_size)

pred2half=rep(NA,T)
icu2half=rep(NA,T)
icl2half=rep(NA,T)
for(t in 1:T){
  sample_gamma=a*rgamma(sample_size,shape=sample$param[1,t,],rate=sample$param[1,t,]/sample$param[2,t,])
  pred2half[t]=mean(sample_gamma)
  icu2half[t]=quantile(sample_gamma,0.975)
  icl2half[t]=quantile(sample_gamma,0.025)
}
```

```{r Gamma3}
devtools::load_all('C:\\Jupyter\\Mestrado\\Pacote\\GDLM - Copy')
level=polynomial_block(order=1,value=c(1,0),D=1/1,by_time = F)
volatility1=polynomial_block(order=1,value=c(0,1),D=1/1,by_time = F)
volatility2=AR_block(order=1,value=c(0,1),D=1/1,W=diag(c(0.1,0)),by_time = F)

outcome=(y-mean(y))**2
a=mean(outcome)
outcome=outcome/a

fitted_data=fit_model(level,volatility1,volatility2,outcome=outcome,family='FGamma')

sample=FFBS_sampling(fitted_data,sample_size)

pred3=rep(NA,T)
icu3=rep(NA,T)
icl3=rep(NA,T)
for(t in 1:T){
  sample_gamma=a*rgamma(sample_size,shape=sample$param[1,t,],rate=sample$param[1,t,]/sample$param[2,t,])
  pred3[t]=mean(sample_gamma)
  icu3[t]=quantile(sample_gamma,0.975)
  icl3[t]=quantile(sample_gamma,0.025)
}
```

```{r fig.height=6, fig.width=8}
((ggplot()+
    geom_point(aes(x=year,y=(y-mean(y))**2,
                  # linetype='NG',
                  shape='Obs.',
                    fill='Obs.',
                    color='Obs.'))+
    geom_line(aes(x=year,y=NG_pred,
                  # linetype='NG',
                    shape='Normal',
                    fill='Normal',
                    color='Normal'))+
    geom_ribbon(aes(x=year,
                    ymin=NG_icl,
                    ymax=NG_icu,
                    # linetype='NG',
                    shape='Normal',
                    fill='Normal',
                    color='Normal'),alpha=0.25)+
    geom_line(aes(x=year,y=pred,
                  # linetype='Gamma',
                    shape='Gamma',
                    fill='Gamma',
                    color='Gamma'))+
    geom_ribbon(aes(x=year,
                    ymin=icl,
                    ymax=icu,
                    # linetype='Gamma',
                    shape='Gamma',
                    fill='Gamma',
                    color='Gamma'),alpha=0.25)+
    geom_line(aes(x=year,y=pred2,
                  # linetype='Gamma',
                    shape='Gamma k=n',
                    fill='Gamma k=n',
                    color='Gamma k=n'))+
    geom_ribbon(aes(x=year,
                    ymin=icl2,
                    ymax=icu2,
                    # linetype='Gamma',
                    shape='Gamma k=n',
                    fill='Gamma k=n',
                    color='Gamma k=n'),alpha=0.25)+
    geom_line(aes(x=year,y=pred2half,
                  # linetype='Gamma',
                    shape='Gamma cod. corrigido',
                    fill='Gamma cod. corrigido',
                    color='Gamma cod. corrigido'),linetype='dashed')+
    geom_ribbon(aes(x=year,
                    ymin=icl2half,
                    ymax=icu2half,
                    # linetype='Gamma',
                    shape='Gamma cod. corrigido',
                    fill='Gamma cod. corrigido',
                    color='Gamma cod. corrigido'),alpha=0.25,linetype='dashed')+
    geom_line(aes(x=year,y=pred3,
                  # linetype='Gamma',
                    shape='Gamma\nalternativo',
                    fill='Gamma\nalternativo',
                    color='Gamma\nalternativo'))+
    geom_ribbon(aes(x=year,
                    ymin=icl3,
                    ymax=icu3,
                    # linetype='Gamma',
                    shape='Gamma\nalternativo',
                    fill='Gamma\nalternativo',
                    color='Gamma\nalternativo'),alpha=0.25)+
    geom_line(aes(x=year,y=mean_gamma_gibbs,
                  # linetype='Gamma',
                  shape='Gamma gibbs',
                  fill='Gamma gibbs',
                  color='Gamma gibbs'))+
    geom_ribbon(aes(x=year,
                    ymin=icl_gamma_gibbs,
                    ymax=icu_gamma_gibbs,
                    # linetype='Gamma',
                  shape='Gamma gibbs',
                  fill='Gamma gibbs',
                  color='Gamma gibbs'),alpha=0.25)+
    scale_shape('')+
    scale_fill_hue('')+
    scale_color_hue('Modelo')+
    scale_x_date('Year',breaks=year_label,labels=function(x){substr(x,1,4)},expand=c(0,0))+
    scale_y_continuous('Estimated value')+
    # coord_cartesian(ylim=c(0,0.5))+
    theme_bw()+
    theme(text=element_text(size=font_size,family=family_font)))+
  labs(title='Ajuste dos dados observados')) %>% ggplotly
```

De modo geral, temos que o ajuste Gamma com Gibbs é essencialmente idêntico ao ajuste Normal, pois a estimativa de $\phi$ no modelo Gamma com Gibbs é muito concentrada em $\frac{1}{2}$, isto é, $(y_i-\bar{y})^2$ acaba tendo distribuição aproximadamente $\chi^2$ com (aproximadamente) o mesmo parâmetro de escala nos dois modelos. Vale destacar que o ajuste no modelo Normal assume implicitamente que $\phi=1/2$, em contrapartida, o ajuste no modelo Gamma (com ou sem Gibbs) assume que $\mu=\bar{y}$, isto é, os dois modelos podem ser considerados como casos especiais de um modelo mais geral onde $\mu$ e $\phi$ são desconhecidos, sendo que cada modelo impõe um restrição em algum dos parâmetros e, dado a natureza dos dados, as duas restrições são válidas.

O ajuste Gamma usando a abordagem $k$-paramétrica pura (i.e., sem Gibbs), é, de certa forma, semelhante aos demais ajustes, mas com uma incerteza muito maior. Esse aumento de incerteza se deve especificamente ao fato de que a estimativa do parâmetro $\phi$ usando a abordagem $k$-paramétrica pura deixa muito a desejar em comparação com o ajuste com Gibbs. Dito isso, o acréscimo de incerteza na distribuição de $\phi$ não se traduz em um acréscimo de mesmo magnitude na incerteza associada à distribuição preditiva do dado (como pode ser visto no gráfico), i.e., enquando a estimação de $\phi$ é muito ruim no ajuste sem Gibbs, a distribuição preditiva das observações parece minimamente aceitável.
